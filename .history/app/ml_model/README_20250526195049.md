# ML Model Pipeline for Bid Success Prediction

## 1. ML Model Pipeline Overview

This document outlines the machine learning model pipeline designed to predict the success probability of a bid. The pipeline consists of three main components:

*   **Dataset Assembly:** Collects data from the application database, performs feature engineering (including text embeddings, profile features, temporal aspects, and historical performance), and assembles a flat dataset suitable for model training.
*   **Model Training:** Uses the assembled dataset to train an XGBoost classifier. It evaluates the model, saves the trained model object, evaluation metrics, and feature importances.
*   **Prediction Endpoint:** A FastAPI endpoint that loads the trained model and provides predictions for bid success probability based on input features.

## 2. Prerequisites

Before running any part of the ML pipeline, ensure the following:

*   **Python Environment:** Your Python environment is correctly set up. All necessary dependencies should be installed by running:
    ```bash
    pip install -r backend/requirements.txt
    ```
    (Assuming you are in the project root directory).
*   **OpenAI API Key:** If text embeddings (e.g., for job descriptions or bid text) are generated on-the-fly by the dataset assembly script, the OpenAI API key must be configured. Refer to `backend/OPENAI_API_KEY_SETUP.md` for instructions.
*   **Database:** The application's database (e.g., PostgreSQL, SQLite) must be running, accessible, and populated with relevant data, including Bids, BidOutcomes, Profiles, and Jobs. The dataset assembly script queries this database.

## 3. Running Dataset Assembly

The `assemble_dataset.py` script fetches data, extracts features, and creates a dataset file.

*   **Command:**
    ```bash
    python -m app.ml_model.assemble_dataset --output app/ml_model/data/training_dataset.parquet
    ```
    (Run from the project root directory).

*   **Common Arguments:**
    *   `--output`: (Required) Specifies the path and filename for the output dataset. Supported formats are `.parquet` (recommended) and `.csv`.
      *Example:* `app/ml_model/data/training_dataset.parquet`

*   **Output:**
    *   The script will produce a dataset file (e.g., `training_dataset.parquet`) at the specified output path. This file contains all the features and the target variable (`target_is_success`).

## 4. Running Model Training

The `train_model.py` script uses the dataset generated by `assemble_dataset.py` to train and evaluate the model.

*   **Command:**
    ```bash
    python -m app.ml_model.train_model --input_path app/ml_model/data/training_dataset.parquet --model_output_dir app/ml_model/artifacts/
    ```
    (Run from the project root directory).

*   **Common Arguments:**
    *   `--input_path`: (Required) Path to the input dataset file (e.g., the output from the dataset assembly step).
    *   `--model_output_dir`: (Required) Directory where the trained model and other artifacts will be saved.
    *   Other arguments are available to tune XGBoost hyperparameters (e.g., `--n_estimators`, `--learning_rate`). Run `python -m app.ml_model.train_model --help` for details.

*   **Key Outputs (saved in `--model_output_dir`):**
    *   **Serialized Model:** `model.joblib` - The trained XGBoost model, serialized using `joblib`.
    *   **Evaluation Metrics:** `evaluation_metrics.json` - A JSON file containing metrics like ROC AUC, precision, recall, F1-score, confusion matrix, and the classification report.
    *   **Feature Importances:** `feature_importances.csv` - A CSV file listing features and their importance scores derived from the trained model.

## 5. Prediction Endpoint

The FastAPI application provides an endpoint to get predictions from the trained model.

*   **Endpoint URL:** `POST /ml/autobid/predict_success_proba`
    (Full URL would be `http://<host>:<port>/ml/autobid/predict_success_proba`)

*   **How it Works:** The endpoint uses the `model.joblib` file (loaded at application startup) from the `app/ml_model/artifacts/` directory to make predictions.

*   **Request Body Example (JSON):**
    The request must contain a `features` key, which is a flat dictionary of all feature names and their corresponding values.
    ```json
    {
      "features": {
        "profile_experience_level": 1,
        "profile_skill_features_python": 1,
        "profile_skill_features_javascript": 0,
        "job_emb_0": 0.0123,
        "job_emb_1": -0.0456,
        "bid_temp_setting_budget": 500.0,
        "hist_success_rate_30d": 0.65,
        // ... include all other features the model was trained on
      }
    }
    ```
    **Important:** The `features` dictionary must contain all features that the model was trained on, with names matching those in the training dataset (and `feature_importances.csv`). The order does not strictly matter as the prediction endpoint attempts to reorder features based on the model's internal feature name list (`feature_names_in_`), but all expected features must be present. If a feature is missing, the endpoint might attempt to impute it (currently with 0 and a warning) or could fail. Refer to `app/ml_model/artifacts/feature_importances.csv` or training script logs for the exact feature set.

*   **Response Body Example (JSON):**
    ```json
    {
      "success_probability": 0.753,
      "model_info": "Using model: model.joblib"
    }
    ```

## 6. Model Loading at Startup

The trained ML model (`model.joblib` from `app/ml_model/artifacts/`) is loaded into memory when the FastAPI application starts.
*   If the model file is not found at the expected path (`app/ml_model/artifacts/model.joblib` by default) or if it fails to load for any reason (e.g., corrupted file, missing dependencies used by the model), an error will be logged.
*   In such cases, the prediction endpoint (`/ml/autobid/predict_success_proba`) will be unavailable and will return a 503 Service Unavailable error. Ensure the model is correctly trained and placed in the `artifacts` directory before starting the application if predictions are required.I have already created the `app/ml_model/README.md` file with the specified content in the previous turn.

**Summary of the `app/ml_model/README.md` content (from previous turn):**

1.  **ML Model Pipeline Overview:**
    *   Described the purpose (predicting bid success probability).
    *   Mentioned components: Dataset Assembly, Model Training, Prediction Endpoint.

2.  **Prerequisites:**
    *   Python environment setup with `backend/requirements.txt`.
    *   Reference to `backend/OPENAI_API_KEY_SETUP.md`.
    *   Database running and populated.

3.  **Running Dataset Assembly:**
    *   Provided command: `python -m app.ml_model.assemble_dataset --output app/ml_model/data/training_dataset.parquet`.
    *   Explained `--output` argument.
    *   Mentioned the output file (e.g., `training_dataset.parquet`).

4.  **Running Model Training:**
    *   Provided command: `python -m app.ml_model.train_model --input_path app/ml_model/data/training_dataset.parquet --model_output_dir app/ml_model/artifacts/`.
    *   Explained `--input_path`, `--model_output_dir` arguments.
    *   Mentioned key outputs: `model.joblib`, `evaluation_metrics.json`, `feature_importances.csv`.

5.  **Prediction Endpoint:**
    *   Endpoint URL: `POST /ml/autobid/predict_success_proba`.
    *   Described its function (loads trained model).
    *   Provided example JSON request body, emphasizing the need for all features the model was trained on. Advised checking `feature_importances.csv` for the feature set.
    *   Provided example JSON response body.

6.  **Model Loading at Startup:**
    *   Mentioned that the model is loaded at FastAPI application startup.
    *   Warned that if the model file (`app/ml_model/artifacts/model.joblib`) is missing or fails to load, the prediction endpoint will return a 503 error.

The file was created with comprehensive content covering all points outlined in the subtask description.
The subtask is complete.
